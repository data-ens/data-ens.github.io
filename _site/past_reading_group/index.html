<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="ENS-CFM Data Science Chair">

    <!-- Loading mathjax -->
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>


    <title>Past - ENS-CFM Data Science Chair</title>

    <link rel="canonical" href="http://localhost:4000/past_reading_group/">

    <!-- Favicon -->
    <link rel="icon" type="image/png" href="/img/favicon.png">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/clean-blog.css">

    <!-- Custom Fonts -->
    <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href='http://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

    <script src="/js/jquery.min.js "></script>

    <link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="ENS-CFM Data Science Chair" />
    
    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>


<body>

    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Home</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">



                <li>
                    <a href="/seminar">Colloquium</a>
                </li>
				<li>
                    <a href="/reading_group">Reading Group</a>
                </li>
                <li>
                    <a href="/jobs">Jobs</a>
                </li>
                  <li>
                        <a href="https://challengedata.ens.fr">Challenge Data</a>
                  </li>
                  <li>
                        <a href="/coming">Coming</a>
                  </li>

                <!--

                
                <li>
                    <a href="/coming/">Coming to the seminar</a>
                </li>
                
                <li>
                    <a href="/conference-2016-12-15/">Inauguration of the Chair CFM-ENS</a>
                </li>
                
                <li>
                    <a href="/conference-2017-12-08/">Special Afternoon ''Data Science in ENS'' </a>
                </li>
                
                <li>
                    <a href="/">Data @ ENS</a>
                </li>
                
                <li>
                    <a href="/jobs/">Laplace Junior Professor Chair in Data Science</a>
                </li>
                
                <li>
                    <a href="/next/">Next</a>
                </li>
                
                <li>
                    <a href="/past/">Past</a>
                </li>
                
                <li>
                    <a href="/past_reading_group/">Past</a>
                </li>
                
                <li>
                    <a href="/reading_group/">Laplace Reading Group</a>
                </li>
                
                <li>
                    <a href="/seminar/">Data Science Colloquium</a>
                </li>
                
                <li>
                    
                </li>
                
                <li>
                    
                </li>
                
                -->
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>


    <!-- Page Header -->
<header class="intro-header" style="background-image: url('/img/ens3.png')">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="site-heading">
                    <h1>Past</h1>
                    <hr class="small">
                    <span class="subheading">Past reading groups</span>
                </div>
            </div>
        </div>
    </div>
</header>



<!-- Main Content -->
<div class="container">
	<div class="row">
		<div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
			<p>You can find below the list of past Laplace reading groups.</p>

<p>
  Mar. 16th, 2018, <a href="https://hal.archives-ouvertes.fr/search/index/q/*/authFullName_s/Marine+Le+Morvan">Marine Le Morvan</a> (Mines-Paristech)
  <br />
  <b>Title:</b> <i>Scaling up the LASSO with interaction features</i><br />
  <b>Abstract:</b> Learning sparse linear models with two-way interactions is desirable in many application domains such as genomics. l1-regularised linear models are popular to estimate sparse models, yet standard implementations fail to address specifically the quadratic explosion of candidate two-way interactions in high dimensions, and typically do not scale to genetic data with hundreds of thousands of features. Here we present WHInter, a working set algorithm to solve large l1- regularised problems with two-way interactions for binary design matrices. The novelty of WHInter stems from a new bound to efficiently identify working sets while avoiding to scan all features, and on fast computations inspired from solutions to the maximum inner product search problem. We apply WHInter to simulated and real genetic data and show that it is more scalable and two orders of magnitude faster than the state of the art.
  </p>

<p>
  Feb. 16th, 2018, <a href=""><a href="https://tomas-angles.github.io/">Tomas Angles</a>, <a href="https://audeg.github.io/">Aude Genevay</a></a> (ENS (DI, DMA))
  <br />
  <b>Title:</b> <i>Learning generative models beyond GANs</i><br />
  <b>Abstract:</b> Generative Models (i.e. high dimensional probabilistic models that are supported on low dimensional manifolds) have become a popular topic in machine learning after the now famous paper on Generative Adversarial Networks (Goodfellow et al. ‘14) that introduced an intuitive algorithm to learn those types of models to generate images resembling those of a given dataset. This two part tutorial will start by an introduction to generative models, and focus on some of their theoretical aspects such as structure in the latent space, and an auto-encoding perspective. The second part will focus on learning such models with algorithms that minimize a certain divergence between the model distribution and the ‘true’ distribution of the data. This state-of-the-art approach has a strong connection to the     original GAN algorithm but is both more stable and better formulated from a mathematical point of view.
  </p>

<p>
  Jan. 12th, 2018, <a href="http://www.augustincosse.com/">Augustin Cosse</a> (ENS, DMA)
  <br />
  <b>Title:</b> <i>Semidefinite programming in the era of big data</i><br />
  <b>Abstract:</b> Semidefinite programming (SDP) has now emerged as a powerful tool to derive approximations to hard problems (such as maxCut), or as a stable algorithm to compute exact solutions to some particular (computationally tractable) instances of such problems (such as in phase retrieval and matrix completion).
The work of Shor, Nesterov, Parrilo and Lasserre brought semidefinite programming to another level by introducing hierarchies of semidefinite programs. In those hierarchies, an original polynomial optimization problem is approximated by a sequence of SDPs on variables of increasing size. Despite their theoretical interest in terms of approximability and stability, the use of such hierarchies is hindered by the size of the variables involved.
In this talk I will address applications of semidefinite programming to some large scale problems from engineering and information theory. In particular, I will start by discussing how SDP hierarchies can be used to improve the current convex relaxation for rank one matrix completion which is based on the minimization of the nuclear norm. Going against the conventional wisdom, I will also discuss possible scalable numerical schemes for those hierarchies. As additional applications, I will briefly address inverse scattering as well as deconvolution and super-resolution.
  </p>

<p>
  Dec. 18th, 2017, <a href="http://www.cs.technion.ac.il/~elad/">Michael Elad</a> (Technion)
  <br />
  <b>Title:</b> <i>Sparse Modeling in Image Processing and Deep Learning</i><br />
  <b>Abstract:</b> Sparse approximation is a well-established theory, with a profound impact on the fields of signal and image processing. In this talk we start by presenting this model and its features, and then turn to describe two special cases of it – the convolutional sparse coding (CSC) and its multi-layered version (ML-CSC). Amazingly, as we will carefully show, ML-CSC provides a solid theoretical foundation to … deep-learning. Alongside this main message of bringing a theoretical backbone to deep-learning, another central message that will accompany us throughout the talk: Generative models for describing data sources enable a systematic way to design algorithms, while also providing a complete mechanism for a theoretical analysis of these algorithms' performance. This talk is meant for newcomers to this field - no prior knowledge on sparse approximation is assumed.
  </p>

<p>
  Nov. 24th, 2017, <a href="http://www.caam.rice.edu/~hand/">Paul Hand</a> (Rice University)
  <br />
  <b>Title:</b> <i>Deep Compressed Sensing</i><br />
  <b>Abstract:</b> Combining principles of compressed sensing with deep neural network-based generative image priors has recently been empirically shown to require 10X fewer measurements than traditional compressed sensing in certain scenarios. As deep generative priors (such as those obtained via generative adversarial training) improve, analogous improvements in the performance of compressed sensing and other inverse problems may be realized across the imaging sciences. In joint work with Vladislav Voroninski, we provide a theoretical framework for studying inverse problems subject to deep generative priors. In particular, we prove that with high probability, the non-convex empirical risk objective for enforcing random deepgenerative priors subject to compressive random linear observations of the last layer of the generator has no spurious local minima, and that for a fixed network depth, these guarantees hold at order-optimal sample complexity.
  </p>

<p>
  Oct. 20th, 2017, <a href="https://www.stat.berkeley.edu/~epurdom/">Elizabeth Purdom</a> (Berkeley)
  <br />
  <b>Title:</b> <i>Robust strategies for analysis of single cell mRNA data</i><br />
  <b>Abstract:</b> mRNA sequencing of single cells is a relatively recent biological technology that allows researchers to query what genes are active in a single cell. This allows for many detailed biological queries that were not possible previously. However, because of the complexities of the experimental process, single cell mRNA-Seq results in quite noisy measurements. In this talk we will introduce for a general audience the data that is being produced and discussed the data challenges that are present in this data in the area of clustering and other forms of estimation. We will then introduce some of our strategies for the analysis of single cell mRNA-Seq.
  </p>


		</div>
	</div>
</div>

<hr>

    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">

                    <li>
                        <a href="/feed.xml">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                    
                    
                    <li>
                        <a href="https://github.com/data-ens">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                    
                </ul>
                <!--
                  <p class="copyright text-muted">Copyright &copy; ENS-CFM Data Science Chair 2018</p>
                -->
            </div>
        </div>
    </div>
</footer>

<!-- jQuery
<script src="/js/jquery.min.js "></script>
-->

<!-- Bootstrap Core JavaScript -->
<script src="/js/bootstrap.min.js "></script>

<!-- Custom Theme JavaScript -->
<script src="/js/clean-blog.min.js "></script>




<!-- Google analytics -->
<script src="http://www.google-analytics.com/urchin.js" type="text/javascript">
</script>
<script type="text/javascript">
_uacct = "UA-781488-2";
urchinTracker();
</script>


</body>

</html>
