- speaker: "<a href='https://tomas-angles.github.io/'>Tomas Angles</a>, <a href='https://audeg.github.io/'>Aude Genevay</a>"
  date: Feb. 16th, 2018
  time: 10h30-12h00
  room: "Room W, DMA, ENS (45 rue d'Ulm, 4th floor)"
  affiliation: "ENS, DI, DMA"
  title: "Learning generative models beyond GANs"
  abstract: "Generative Models (i.e. high dimensional probabilistic models that are supported on low dimensional manifolds) have become a popular topic in machine learning after the now famous paper on Generative Adversarial Networks (Goodfellow et al. ‘14) that introduced an intuitive algorithm to learn those types of models to generate images resembling those of a given dataset.
  This two part tutorial will start by an introduction to generative models, and focus on some of their theoretical aspects such as structure in the latent space, and an auto-encoding perspective.
  The second part will focus on learning such models with algorithms that minimize a certain divergence between the model distribution and the ‘true’ distribution of the data. This state-of-the-art approach has a strong connection to the     original GAN algorithm but is both more stable and better formulated from a mathematical point of view."

- speaker: "Augustin Cosse"
  date: Jan. 12th, 2018
  time: 14h00-15h00
  room: "Room W, DMA, ENS (45 rue d'Ulm, 4th floor)"
  affiliation: "ENS, DMA"
  url: "http://www.augustincosse.com/"
  title: "Semidefinite programming in the era of big data"
  abstract: "Semidefinite programming (SDP) has now emerged as a powerful tool to
  derive approximations to hard problems (such as maxCut), or as a stable
  algorithm to compute exact solutions to some particular (computationally
  tractable) instances of such problems (such as in phase retrieval and
  matrix completion).
  
  The work of Shor, Nesterov, Parrilo and Lasserre brought semidefinite
  programming to another level by introducing hierarchies of semidefinite
  programs. In those hierarchies, an original polynomial optimization
  problem is approximated by a sequence of SDPs on variables of increasing
  size. Despite their theoretical interest in terms of approximability and
  stability, the use of such hierarchies is hindered by the size of the
  variables involved.

  In this talk I will address applications of semidefinite programming to
  some large scale problems from engineering and information theory. In
  particular, I will start by discussing how SDP hierarchies can be used to
  improve the current convex relaxation for rank one matrix completion which
  is based on the minimization of the nuclear norm. Going against the
  conventional wisdom, I will also discuss possible scalable numerical
  schemes for those hierarchies. As additional applications, I will briefly
  address inverse scattering as well as deconvolution and super-resolution."

- speaker: "Michael Elad"
  date: Dec. 18th, 2017
  time: 14h00-15h00
  room: "Room W, DMA, ENS (45 rue d'Ulm, 4th floor)"
  affiliation: "Technion"
  url: "http://www.cs.technion.ac.il/~elad/"
  title: "Sparse Modeling in Image Processing and Deep Learning"
  abstract: "Sparse approximation is a well-established theory, with a profound impact on the fields of signal and image processing. In this talk we start by presenting this model and its features, and then turn to describe two special cases of it – the convolutional sparse coding (CSC) and its multi-layered version (ML-CSC). Amazingly, as we will carefully show, ML-CSC provides a solid theoretical foundation to … deep-learning. Alongside this main message of bringing a theoretical backbone to deep-learning, another central message that will accompany us throughout the talk: Generative models for describing data sources enable a systematic way to design algorithms, while also providing a complete mechanism for a theoretical analysis of these algorithms' performance. This talk is meant for newcomers to this field - no prior knowledge on sparse approximation is assumed."

- speaker: "Paul Hand"
  date: Nov. 24th, 2017
  time: 14h00-15h00
  room: "Salle R, passage rouge 2e sous-sol"
  affiliation: "Rice University"
  url: "http://www.caam.rice.edu/~hand/"
  title: "Deep Compressed Sensing"
  abstract: "Combining principles of compressed sensing with deep neural network-based generative image priors has recently been empirically shown to require 10X fewer measurements than traditional compressed sensing in certain scenarios. As deep generative priors (such as those obtained via generative adversarial training) improve, analogous improvements in the performance of compressed sensing and other inverse problems may be realized across the imaging sciences. In joint work with Vladislav Voroninski, we provide a theoretical framework for studying inverse problems subject to deep generative priors. In particular, we prove that with high probability, the non-convex empirical risk objective for enforcing random deepgenerative priors subject to compressive random linear observations of the last layer of the generator has no spurious local minima, and that for a fixed network depth, these guarantees hold at order-optimal sample complexity."

- speaker: "Elizabeth Purdom"
  date: Oct. 20th, 2017
  time: 13h30-14h30
  room: "W, DMA, ENS (45 rue d'Ulm)"
  affiliation: "Berkeley"
  url: "https://www.stat.berkeley.edu/~epurdom/"
  title: "Robust strategies for analysis of single cell mRNA data"
  abstract: "mRNA sequencing of single cells is a relatively recent biological technology that allows researchers to query what genes are active in a single cell. This allows for many detailed biological queries that were not possible previously. However, because of the complexities of the experimental process, single cell mRNA-Seq results in quite noisy measurements. In this talk we will introduce for a general audience the data that is being produced and discussed the data challenges that are present in this data in the area of clustering and other forms of estimation. We will then introduce some of our strategies for the analysis of single cell mRNA-Seq."