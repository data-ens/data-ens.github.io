

- speaker: "Yue M. Lu"
  date: Sept. 17th, 2019
  time: 12h00-13h00
  room: "CONF IV (physic dpt, Rue Lhomond)"
  affiliation: "Toyota Technological Institute at Chicago"
  url: "https://ttic.uchicago.edu/~nati/"
  title: "Optimization's Hidden Gift to Learning: Implicit Regularization"
  abstract: "It is becoming increasingly clear that implicit regularization
  afforded by the optimization algorithms play a central role in machine
  learning, and especially so when using large, deep, neural networks.
  We have a good understanding of the implicit regularization afforded
  by stochastic approximation algorithms, such as SGD, for convex problem,
  and we understand and can characterize the implicit bias of
  different algorithms, and can design algorithms with specific biases.
  But in this talk I will focus on implicit biases of local search algorithms
  for non-convex underdetermined problem, such as deep networks.
  In an effort to uncover the implicit biases of gradient-based optimization
  of neural networks, which holds the key to their empirical success, I will discuss recent
  work on implicit regularization for matrix factorization, linear convolutional networks,
  and two-layer ReLU networks, as well as a general bottom-up understanding
  on implicit regularization in terms of optimization geometry."
